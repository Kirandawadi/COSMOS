{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/docs/spectra_ws.html\n"
     ]
    }
   ],
   "source": [
    "bulk_data = [\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"collection\": 85,\n",
    "            \"url\": \"exo.mast.stsci.edu/docs/\",\n",
    "            \"excluded\": False,\n",
    "            \"title\": \"Root URL is this one\",\n",
    "        },\n",
    "        \"children\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "def add_to_root_node(path, title, root_node):\n",
    "    \"\"\"Recursively figure out where to add a URL to the root node.\"\"\"\n",
    "    path_parts = path.split('/')\n",
    "    if path_parts[0] == '':\n",
    "        path_parts = path_parts[1:]\n",
    "    if path_parts[0] == '':\n",
    "        path_parts = path_parts[1:]\n",
    "    if path_parts[-1] == '':\n",
    "        path_parts = path_parts[:-1]\n",
    "    if path_parts[-1] == '':\n",
    "        path_parts = path_parts[:-1]\n",
    "    if len(path_parts) == 0:\n",
    "        return\n",
    "    if len(path_parts) == 1:\n",
    "        root_node['children'].append({\n",
    "            \"data\": {\n",
    "                \"collection\": 85,\n",
    "                \"url\": path,\n",
    "                \"excluded\": False,\n",
    "                \"title\": title,\n",
    "            },\n",
    "        })\n",
    "        return\n",
    "    for child in root_node['children']:\n",
    "        if child['data']['url'] == path_parts[0]:\n",
    "            add_to_root_node('/'.join(path_parts[1:]), title, child)\n",
    "            return\n",
    "    new_node = {\n",
    "        \"data\": {\n",
    "            \"collection\": 85,\n",
    "            \"url\": path_parts[0],\n",
    "            \"excluded\": False,\n",
    "            \"title\": path_parts[0],\n",
    "        },\n",
    "        \"children\": []\n",
    "    }\n",
    "    root_node['children'].append(new_node)\n",
    "    add_to_root_node('/'.join(path_parts[1:]), title, new_node)\n",
    "\n",
    "with open('urls.jsonl', 'r') as jsonfile:\n",
    "    urls = jsonfile.readlines()\n",
    "    root_node = {\n",
    "        \"data\": {\n",
    "            \"collection\": 85,\n",
    "            \"url\": json.loads(urls[0])['url'],\n",
    "            \"excluded\": False,\n",
    "            \"title\": json.loads(urls[0])['title'],\n",
    "        },\n",
    "        \"children\": []\n",
    "    }\n",
    "    bulk_data.append(root_node)\n",
    "\n",
    "    for url in urls[1:]:\n",
    "        url = json.loads(url)\n",
    "        parsed = urlparse(url['url'])\n",
    "        add_to_root_node(parsed.path, url['title'], root_node)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'dvdata', 'kepler', '8394721', 'phaseplot', '?tce=2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/dvdata/kepler/8394721/phaseplot/?tce=2'\n",
    "path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://exo.mast.stsci.edu/api/v0.1/dvdata/kepler/8394721/phaseplot/?tce=2',\n",
       " 'title': 'Phased Light Curve'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node('/root')\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree\n",
    "\n",
    "root = Node('root')\n",
    "\n",
    "def add_to_tree(path, parent=root):\n",
    "    splits = path.split('/')\n",
    "    if splits[0] == '':\n",
    "        parent = root\n",
    "    \n",
    "    for split in splits:\n",
    "        node = Node(split, parent=parent)\n",
    "        add_to_tree('/'.join(splits[1:]), parent=node)\n",
    "\n",
    "with open('urls.jsonl', 'r') as jsonfile:\n",
    "    urls = jsonfile.readlines()\n",
    "\n",
    "    root = Node('root')\n",
    "    for url in urls:\n",
    "        url = json.loads(url)\n",
    "        parsed = urlparse(url['url'])\n",
    "        add_to_tree(parsed.path)\n",
    "\n",
    "print(RenderTree(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('urls.jsonl', 'r') as jsonfile:\n",
    "    urls = jsonfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [urlparse(json.loads(url)['url']).path.split('/')[1:] for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "tree = lambda: defaultdict(tree)\n",
    "\n",
    "def make_tree(lst):\n",
    "    d = tree()    \n",
    "    for x in lst:\n",
    "        curr = d\n",
    "        for item in x:\n",
    "             curr = curr[item]\n",
    "    return d\n",
    "\n",
    "d = make_tree(lst)\n",
    "\n",
    "def make_strs(d, indent=0):\n",
    "     strs = []\n",
    "     for k, v in d.items():\n",
    "         strs.append('    ' * indent + str(k))\n",
    "         strs.extend(make_strs(v, indent+1))\n",
    "     return strs\n",
    "\n",
    "def print_tree(d):\n",
    "    print('\\n'.join(make_strs(d)))\n",
    "\n",
    "# print_tree(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': {'url': 'docs'},\n",
       "  'children': [{'data': {'url': 'spectra_ws.html'}, 'children': []},\n",
       "   {'data': {'url': '_sources'},\n",
       "    'children': [{'data': {'url': 'index.rst.txt'}, 'children': []},\n",
       "     {'data': {'url': 'spectra_ws.rst.txt'}, 'children': []},\n",
       "     {'data': {'url': 'exoplanets_ws.rst.txt'}, 'children': []},\n",
       "     {'data': {'url': 'swagger'},\n",
       "      'children': [{'data': {'url': 'index.rst.txt'}, 'children': []}]},\n",
       "     {'data': {'url': 'dvdata_ws.rst.txt'}, 'children': []},\n",
       "     {'data': {'url': 'getting_started.rst.txt'}, 'children': []}]},\n",
       "   {'data': {'url': 'exoplanets_ws.html'}, 'children': []},\n",
       "   {'data': {'url': 'dvdata_ws.html'}, 'children': []},\n",
       "   {'data': {'url': 'swagger'},\n",
       "    'children': [{'data': {'url': 'index.html'}, 'children': []}]},\n",
       "   {'data': {'url': 'getting_started.html'}, 'children': []},\n",
       "   {'data': {'url': 'index.html'}, 'children': []}]},\n",
       " {'data': {'url': 'api'},\n",
       "  'children': [{'data': {'url': 'v0.1'},\n",
       "    'children': [{'data': {'url': 'dvdata'},\n",
       "      'children': [{'data': {'url': 'kepler'},\n",
       "        'children': [{'data': {'url': '8394721'},\n",
       "          'children': [{'data': {'url': 'info'}, 'children': []},\n",
       "           {'data': {'url': 'tces'}, 'children': []},\n",
       "           {'data': {'url': 'table'}, 'children': []},\n",
       "           {'data': {'url': 'phaseplot'}, 'children': []}]}]},\n",
       "       {'data': {'url': 'tess'},\n",
       "        'children': [{'data': {'url': '388104525'},\n",
       "          'children': [{'data': {'url': 'info'}, 'children': []},\n",
       "           {'data': {'url': 'tces'}, 'children': []},\n",
       "           {'data': {'url': 'table'}, 'children': []}]},\n",
       "         {'data': {'url': 'info'}, 'children': []}]}]},\n",
       "     {'data': {'url': 'exoplanets'},\n",
       "      'children': [{'data': {'url': 'identifiers'}, 'children': []},\n",
       "       {'data': {'url': 'TrES-2%20b'},\n",
       "        'children': [{'data': {'url': 'properties'}, 'children': []}]}]},\n",
       "     {'data': {'url': 'spectra'},\n",
       "      'children': [{'data': {'url': 'Hat-P-11%20b'},\n",
       "        'children': [{'data': {'url': 'file'},\n",
       "          'children': [{'data': {'url': 'HAT-P-11b_transmission_Fraine2014.txt'},\n",
       "            'children': []}]},\n",
       "         {'data': {'url': 'filelist'}, 'children': []},\n",
       "         {'data': {'url': 'plot'}, 'children': []}]}]}]}]}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_bulk_data(d, level=0):\n",
    "    children = []\n",
    "    for k, v in d.items():\n",
    "        if not k:\n",
    "            continue\n",
    "        children.append({\"data\": {\"url\": k,}, \"children\": make_bulk_data(v, level+1)})\n",
    "    return children\n",
    "\n",
    "make_bulk_data(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp311-cp311-macosx_10_9_x86_64.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2022.12.7 charset-normalizer-3.1.0 idna-3.4 requests-2.28.2 urllib3-1.26.15\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n",
      "{'userId': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example to read API and filter data using facets\n",
    "'''\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint URL\n",
    "url = \"https://jsonplaceholder.typicode.com/posts/1\"\n",
    "\n",
    "# Define the facets to filter the API response\n",
    "facets = [\"userId\", \"title\"]\n",
    "\n",
    "# Send a GET request to the API endpoint\n",
    "response = requests.get(url)\n",
    "\n",
    "# If the request was successful, parse the response content as a JSON object\n",
    "if response.status_code == 200:\n",
    "    data = json.loads(response.text)\n",
    "    print(\"data\", data)\n",
    "\n",
    "    # Create a new dictionary with only the specified facets\n",
    "    filtered_data = {facet: data[facet] for facet in facets}\n",
    "\n",
    "    # Print the filtered data\n",
    "    print(filtered_data)\n",
    "else:\n",
    "    print(\"Error: Failed to retrieve data from API\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
